<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<style>
  /* Talk video links */
  a.talk-link:link, a.talk-link:visited {
    color: #1b7f3a;           /* green */
    font-weight: 600;
    text-decoration: none;
  }
  a.talk-link:hover, a.talk-link:active {
    text-decoration: underline;
  }

  /* Code links */
  a.code-link:link, a.code-link:visited {
    color: #b45309;           /* orange */
    font-weight: 600;
    text-decoration: none;
  }
  a.code-link:hover, a.code-link:active {
    text-decoration: underline;
  }
</style>


<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Mahdi Haghifam </title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Menu</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="publication.html">Publications</a></div>
<div class="menu-item"><a href="cv.pdf">CV</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Mahdi Haghifam </h1>
</div>
<table class="imgtable"><tr><td>
<img src="photo/photo.jpg" alt="alt text" width="240px" height="203px" />&nbsp;</td>
<td align="left">
<a href="https://scholar.google.ca/citations?user=WADwBkkAAAAJ&amp;hl=en">[Google Scholar]</a>  <a href="https://github.com/mhaghifam/">[Github]</a>  <a href="https://twitter.com/HaghifamMahdi">[Twitter]</a> <a href="https://www.linkedin.com/in/mahdi-haghifam/">[Linkedin]</a> <br />
Email(preferred): <a href="mailto:haghifam.mahdi@gmail.com">haghifam.mahdi@gmail.com</a> <br />
Email: <a href="mailto:mhaghifam@ttic.edu">mhaghifam@ttic.edu</a> <br />
<br />
<br /></p>
</td></tr></table>
<h2>About Me</h2>
<p>I am a <a href="https://www.ttic.edu/what-is-a-research-assistant-professor/">‪research assistant professor</a>  at the <a href="https://www.ttic.edu/">Toyota Technological Institute at Chicago (TTIC)‬</a>.  I was previously a  <a href="https://shorturl.at/kpquU">Distinguished Postdoctoral Researcher</a> at Khoury College of Computer Sciences at Northeastern University, fortunate to be working  <a href="https://jonathan-ullman.github.io/">Jonathan Ullman‬</a> and <a href="https://www.bu.edu/cs/profiles/adam-smith/">Adam Smith‬</a>. I completed my Ph.D. in Machine Learning (<a href="https://utoronto.scholaris.ca/server/api/core/bitstreams/7b9dd6fe-3d0d-4af6-b2d9-094f822523d6/content">thesis‬</a>) at University of Toronto/  <a href="https://vectorinstitute.ai/">‪Vector Institute‬‬</a> where I was fortunate to be advised by  <a href="http://danroy.org/">‪Daniel M. Roy‬</a>. I also received my B.Sc. and M.Sc. degrees in Electrical Engineering from Sharif University of Technology.</p>

<p>
  During my Ph.D., I had a great time working in industry as an intern at
  <a href="https://deepmind.google/">Google DeepMind</a> (mentored by <a href="http://www.thomas-steinke.net/">Thomas Steinke</a>)
  and <a href="https://www.servicenow.com/research/">ServiceNow Research</a> (mentored by <a href="https://gkdz.org/">Gintare Karolina Dziugaite</a>).
  <a href="#work">See details here</a>.
</p>
  
 <p> Recognitions of my work include a <b>Best Paper Award at ICML 2024</b>, Simons Institute-UC Berkeley Research Fellowship, as well as several honors for graduate research excellence from University of Toronto, including the Henderson and Bassett Research Fellowship and the Viola Carless Smith Research Fellowship. Additionally, I was recognized as a top reviewer at NeurIPS in 2021 and 2023.</p>



  
<h2>Research Overview and Selected Papers </h2>
<p> My research focuses on the foundations and principled algorithm design for ML. More broadly, I work on statistical learning theory, optimization theory, statistics, and information theory. The central goal of my research is to address practical challenges in ML by developing tools and algorithms with rigorous theoretical guarantees that assess and ensure validity. This work is crucial for building trustworthy ML systems in high-stakes applications, where balancing responsible deployment with strong empirical performance is essential. Some of the directions I have been working on:  </p>
<p><font color="purple"><u><b>Generalization in Machine Learning</b></u></font>:  </p>
<ul>
<li><p><a href="https://arxiv.org/abs/1911.02151">Information-Theoretic Generalization Bounds for SGLD via Data-Dependent Estimates</a>   |&nbsp;
<a class="code-link" href="https://github.com/mhaghifam/sgld-genbound-NeurIPS2019-and-2020">[Code]</a> </a>  
<br /> J. Negrea*, <b> M. Haghifam* </b>, G. K. Dziugaite, A. Khisti, D. M. Roy
<br /> Advances in Neural Information Processing Systems (NeurIPS), 2019
<li><p><a href="https://arxiv.org/abs/2004.12983">Sharpened Generalization Bounds based on Conditional Mutual Information and an Application to Noisy, Iterative Algorithms</a>   |&nbsp;
&nbsp;
  <a class="talk-link" href=" https://slideslive.com/38936040/sharpened-generalization-bounds-based-on-conditional-mutual-information-and-an-application-to-noisy-iterative-algorithms?ref=search-presentations">[Talk video]</a> |&nbsp; <a class="code-link" href="https://github.com/mhaghifam/sgld-genbound-NeurIPS2019-and-2020">[Code]</a> </a>  
<br /> M. Haghifam, J. Negrea, A. Khisti, D. M. Roy, G. K. Dziugaite
<br /> Advances in Neural Information Processing Systems (NeurIPS), 2020
</li>
<li><p>  <a href="https://arxiv.org/abs/2111.05275">Towards a Unified Information-Theoretic Framework for Generalization</a>
&nbsp;|&nbsp;
<a class="talk-link" href="https://slideslive.com/38968947/towards-a-unified-informationtheoretic-framework-for-generalization?ref=search-presentations">[Talk video]</a>
&nbsp;
<br /> <b> M. Haghifam </b>, G. K. Dziugaite, S. Moran,  D. M. Roy.
<br /> Advances in Neural Information Processing Systems (NeurIPS), 2021  <font color="blue"><b>(Spotlight, &lt;3% of submissions)</b></font>
</li>
</ul>
<p><font color="purple"><u><b>Memorization and Privacy Attacks</b></u></font>:  </p>
<ul>
<li><p><a href="https://arxiv.org/abs/2402.09327">Information Complexity of Stochastic Convex Optimization: Applications to Generalization and Memorization</a>  &nbsp;|&nbsp;
  <a class="talk-link" href=" https://icml.cc/virtual/2024/oral/35552">[Talk video at ICML'24]</a>
<br /> I. Attias, G. K. Dziugaite,<b> M. Haghifam </b>, R. Livni, D. M. Roy (alphabetic ordering)
<br /> International Conference on Machine Learning (ICML), 2024  <font color="blue"><b>(Oral, Best Paper Award: Top 10 of 10,000 submissions)</b></font>
</li>
<li><p><a href="https://arxiv.org/abs/2508.19458">The Sample Complexity of Membership Inference and Privacy Auditing</a>
<br /> <b>M. Haghifam </b>, A. Smith, J. Ullman <img class="eq" src="eqs/1237943278-130.png" alt="(alphabeta)" style="vertical-align: -5px" />
<br /> Pre-print, 2025 </p>
</li>
<li><p><a href="https://arxiv.org/abs/2502.17384">On Traceability in <img class="eq" src="eqs/1533415602-130.png" alt="ell_p" style="vertical-align: -6px" /> Stochastic Convex Optimization</a>
<br /> S. Voitovych*, <b>M. Haghifam* </b>, I. Attias, G. K. Dziugaite, R. Livni, D. M. Roy
<br />  Advances in Neural Information Processing Systems (NeurIPS), 2025 <font color="blue"><b>(Spotlight, &lt;3% of submissions)</b></font>
</ul>
<p><font color="purple"><u><b>Differential Privacy</b></u></font>: </p>
<ul>
<li><p><a href="https://arxiv.org/abs/2406.07407">Private Geometric Median &nbsp;|&nbsp;
  <a class="talk-link" href=" https://slideslive.com/39027871/private-geometric-median?ref=search-presentations">[Talk video]</a> |&nbsp;
<a class="code-link" href="https://github.com/mhaghifam/Private-Geometric-Median-NeurIPS2024">[Code]</a> </a>  
<br /> <b> M. Haghifam </b>, T. Steinke, J. Ullman 
<br /> Advances in Neural Information Processing Systems (NeurIPS), 2024 </p>
</li>
<li><p><a href="https://arxiv.org/abs/2305.13209">Faster Differentially Private Convex Optimization via Second-Order Methods</a> |&nbsp;
<a class="code-link" href="https://github.com/mhaghifam/Second-Order-Private-Optimization-NeurIPS2023">[Code]</a>
<br /> A. Ganesh, <b> M. Haghifam </b>, T. Steinke, A. Thakurta (alphabetic ordering)
<br /> Advances in Neural Information Processing Systems (NeurIPS) 2023</p> 
</ul>

 <h2 id="work">Industry Internship Experience</h2>

<div class="internship-entry">
<p><b><a href="https://deepmind.google/">Google DeepMind</a></b>| Research Intern<br>
<i>Mountain View| September 2022 – December 2022</i><br>
Mentors: <a href="http://www.thomas-steinke.net/">Thomas Steinke</a> <br>
- Developed second-order differentially private optimization method achieving 10–40× wall-clock speedups over DP-SGD baselines at comparable accuracy/privacy<br>
- Resulted in publications at NeurIPS 2023 <a href="https://arxiv.org/abs/2305.13209">(link)</a>   <a href="https://github.com/mhaghifam/Second-Order-Private-Optimization-NeurIPS2023">(code)</a> and  ICML 2023 <a href="https://arxiv.org/abs/2302.09483">(link)</a> 
</div>

<div class="internship-entry">
<p><b><a href="https://www.servicenow.com/research/">ServiceNow Research</a></b> | Research Intern<br>
<i>Toronto  | November 2020 – March 2021</i><br>
Mentor: <a href="https://gkdz.org/">Gintare Karolina Dziugaite</a><br>
- Studied the connections between different generalization approaches in ML<br>
- Resulted in publication in NeurIPS 2021 (Spotlight) <a href="https://arxiv.org/abs/2111.05275">(link)</a></p>
</div>

<div class="internship-entry">
<p><b><a href="https://www.servicenow.com/research/">ServiceNow Research</a></b> | Research Intern<br>
<i>Toronto  | February 2019 – May 2019</i><br>
Mentor: <a href="https://gkdz.org/">Gintare Karolina Dziugaite</a><br>
- Proposed data-dependent generalization estimates for noisy SGD / SGLD using gradient disagreement.  NeurIPS 2019 <a href="https://arxiv.org/abs/1911.02151">(link)</a><br>
- The proposed method achieves for the first time non-vacuous generalization bound in various modern ML setups. <br>
- Built generalization-prediction tools in TensorFlow for CNNs and MLP on image classification tasks.  <a href="https://github.com/mhaghifam/sgld-genbound-NeurIPS2019-and-2020">(code)</a></p>
</div>

  
<h2>Contact Me!</h2>
<p>Feel free to reach out if you'd like to discuss research ideas. Also, I'm happy to offer guidance and support to those applying to graduate programs, especially individuals who might not typically have access to such assistance</p>
</td>
</tr>
</table>
</body>
</html>


































































